<img width="1024" height="233" alt="image" src="https://github.com/user-attachments/assets/e210dcce-57f2-4470-a895-780896dbe45f" />

# ğŸ¯ Predictive Deception â€” LLM-based Command Anticipation in SSH Honeypots

---

## ğŸ¯ Obiettivo del progetto: *Predictive Deception per Honeypot*

Gli honeypot tradizionali osservano e registrano ciÃ² che lâ€™attaccante fa **solo dopo** lâ€™esecuzione di un comando.  
Questo progetto introduce un nuovo paradigma: sfruttare un **LLM** per trasformare lâ€™honeypot da sistema passivo a **sistema predittivo**.

### ğŸš€ Idea chiave  
Un modello di linguaggio (es. CodeLlama, Llama 3, Gemini, Mistral) analizza la sequenza dei comandi dell'attaccante e **predice il prossimo comando** con alta accuratezza, *prima* che venga digitato.

### ğŸ” PerchÃ© Ã¨ rivoluzionario  
Grazie alla predizione dei comandi, lâ€™honeypot puÃ²:

- ğŸª¤ **Preparare deception mirate in anticipo**  
  Creare file fake, directory esca, configurazioni fittizie, output manipolati **prima** che lâ€™attaccante tenti di accedervi.

- ğŸ¯ **Attivare trigger intelligenti e invisibili**  
  Canary tokens, logging avanzato, honey-credentials, environment spoofingâ€¦ tutto al momento giusto.

- ğŸ§  **Aumentare lâ€™ingaggio dellâ€™attaccante**  
  Il sistema diventa piÃ¹ realistico, piÃ¹ coerente e piÃ¹ credibile, favorendo lâ€™emergere di comportamenti complessi e tecniche avanzate.

- ğŸ“ˆ **Potenziare la threat intelligence**  
  Analisi predittiva delle campagne, riconoscimento di tool automatizzati, profilo comportamentale degli attaccanti e dataset di alto valore.

### ğŸ§© In sintesi  
Il progetto trasforma lâ€™honeypot in un sistema **proattivo**, capace non solo di osservare ma di **anticipare**, manipolare e studiare il comportamento dellâ€™attaccante con un livello di controllo mai visto prima.

---

## ğŸ“¦ Requirements

Il progetto utilizza LLM, RAG e dataset generati da honeypot Cowrie.  
Questi sono i requisiti minimi e completi per eseguire preprocessing, predizione e fine-tuning.

### ğŸ”§ Core Dependencies
- `python-dotenv`
- `tqdm`
- `requests`
- `jsonlines`
- `pandas`

### ğŸ§  RAG & Embeddings
- `chromadb`
- `sentence-transformers`

### ğŸ¤– LLM APIs (Gemini / OpenAI / HF)
- `openai`
- `google-genai`
- `transformers`
- `tokenizers`
- `safetensors`

### ğŸ§ª Fine-Tuning (CodeLlama / PEFT)
- `torch`
- `accelerate`
- `datasets`
- `peft`
- `bitsandbytes`

### ğŸ“Š Machine Learning Utilities
- `scikit-learn`
- `numpy`

---

## ğŸ“ Struttura del repository
```bash
## ğŸ“ Struttura del repository

```bash
Predictive_deception/
â”‚
â”œâ”€â”€ chroma_storage/                     # Storage locale per ChromaDB (RAG)
â”‚
â”œâ”€â”€ data/                               # Dataset Cowrie grezzi o scaricati
â”‚
â”œâ”€â”€ fine_tuning/                        # Script per preparazione e training modelli
â”‚   â””â”€â”€ convert_sessions_to_finetune.py # Converte sessioni SSH in dataset per LLM
â”‚
â”œâ”€â”€ google-cloud-sdk/                   # SDK Google (opzionale, per storage/compute)
â”‚
â”œâ”€â”€ inspectDataset/                     # Analisi e pulizia dataset Cowrie
â”‚   â”œâ”€â”€ analyze_and_clean.py            # Pulizia e normalizzazione eventi
â”‚   â””â”€â”€ merge_cowrie_datasets.py        # Merge file Cowrie multipli
â”‚
â”œâ”€â”€ output/                             # File prodotti dal progetto (dataset, risultati)
â”‚
â”œâ”€â”€ prompting/                          # Modulo per valutazione predittiva LLM
â”‚   â”œâ”€â”€ core_RAG.py                     # Motore RAG locale
â”‚   â”œâ”€â”€ core_topk.py                    # Motore top-k senza RAG
â”‚   â”œâ”€â”€ evaluate_GEMINI_RAG.py          # Valutazione Gemini con RAG
â”‚   â”œâ”€â”€ evaluate_GEMINI_topk.py         # Valutazione Gemini top-k
â”‚   â”œâ”€â”€ evaluate_ollama_RAG.py          # Valutazione modelli locali (Ollama) con RAG
â”‚   â”œâ”€â”€ evaluate_ollama_topk.py         # Valutazione Ollama top-k
â”‚   â””â”€â”€ utils.py                        # Funzioni condivise (tokenizzazione, parsing, ecc.)
â”‚
â”œâ”€â”€ utilities_script/                   # Script di utilitÃ  e preprocessing
â”‚   â”œâ”€â”€ download_zenodo.py              # Download dataset pubblici da Zenodo
â”‚   â”œâ”€â”€ inspect_cowrie_json.py          # Ispezione JSON Cowrie per debugging
â”‚   â””â”€â”€ vector_research.py              # Analisi vettori, embedding e RAG debugging
â”‚
â”œâ”€â”€ venv/                               # Ambiente virtuale Python (non va pushato)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ google-cloud-cli-darwin-x86_64.tar.gz
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ todo.txt


```

â¸»
---

## ğŸ§­ Workflow del progetto

## ğŸ§­ Workflow del progetto

| Step | Script | Input | Output | Descrizione |
|------|--------|--------|---------|-------------|
| 1ï¸âƒ£ | `download_zenodo.py` | â€” | `data/*.json` | Scarica automaticamente i file Cowrie dal dataset Zenodo (record 3687527) |
| 2ï¸âƒ£ | `inspect_cowrie_json.py` | `data/*.json` | â€” | Ispezione e validazione della struttura dei file JSON grezzi |
| 3ï¸âƒ£ | `analyze_and_clean.py` | `data/*.json` | `output/cowrie_{RAW,CLEAN}.jsonl` | Analizza singoli file, estrae sessioni e normalizza comandi |
| 4ï¸âƒ£ | `merge_cowrie_datasets.py` | `data/*.json` | `output/cowrie_ALL_RAW.jsonl` / `output/cowrie_ALL_CLEAN.jsonl` | Unisce tutti i file, produce RAW e CLEAN globali, genera statistiche, split train/test |
| 5ï¸âƒ£ | `filter_short_sessions.py` | `output/cowrie_ALL_CLEAN.jsonl` | `output/cowrie_ALL_CLEAN_filtered.jsonl` | Rimuove sessioni troppo brevi (min-len configurabile) |
| 6ï¸âƒ£ | `core_topk.py` | â€” | â€” | Motore predittivo TOP-K (logica comune a Ollama e Gemini) |
| 7ï¸âƒ£ | `core_RAG.py` | â€” + ChromaDB | â€” | Motore RAG: embedding, indicizzazione, ricerca vettoriale e few-shot dinamico |
| 8ï¸âƒ£ | `evaluate_ollama_topk.py` | `output/cowrie_TEST.jsonl` | `output/ollama_topk_results.jsonl` | Valutazione modelli locali Ollama (modalitÃ  TOP-K) |
| 9ï¸âƒ£ | `evaluate_ollama_RAG.py` | `output/cowrie_TEST.jsonl` + ChromaDB | `output/ollama_rag_results.jsonl` | Valutazione modelli Ollama con RAG |
| ğŸ”Ÿ | `evaluate_GEMINI_topk.py` | `output/cowrie_TEST.jsonl` | `output/gemini_topk_results.jsonl` | Valutazione Gemini API (TOP-K) |
| 1ï¸âƒ£1ï¸âƒ£ | `evaluate_GEMINI_RAG.py` | `output/cowrie_TEST.jsonl` + ChromaDB | `output/gemini_rag_results.jsonl` | Valutazione Gemini API con RAG |
| 1ï¸âƒ£2ï¸âƒ£ | `vector_research.py` | qualsiasi JSONL | output debug | Strumento di debug per test embedding, query e qualitÃ  del vector search |
| 1ï¸âƒ£3ï¸âƒ£ | `utils.py` | â€” | â€” | Funzioni condivise: normalizzazione comandi, pulizia, confronto, parsing |
â¸»

## ğŸš€ **Esempi di utilizzo rapido**

1ï¸âƒ£ Merge, Clean e Split del dataset Cowrie:
```bash
python inspectDataset/merge_cowrie_datasets.py --input data --output output/cowrie --want clean
```
2ï¸âƒ£ Generare coppie di predizione (sliding window) per il fine-tuning:
```bash
python build_predictive_pairs.py --input output/cowrie_sessions.jsonl --output output/predictive_pairs.jsonl --context-len 1
```
3ï¸âƒ£ Valutare un modello locale con Ollama (solo TOP-K):
```bash
ollama pull mistral:7b-instruct-q4_0
ollama serve &
python prompting/evaluate_ollama_topk.py --sessions output/cowrie_TEST.jsonl --model mistral:7b-instruct-q4_0 --k 5 --n 200 --context-len 5
```
4ï¸âƒ£ Valutare un modello locale con Ollama + RAG (opzionale):

```bash
python prompting/evaluate_ollama_RAG.py --sessions output/cowrie_TEST.jsonl --index-file output/cowrie_TRAIN.jsonl --model codellama --k 5 --rag-k 3 --context-len 5 --n 200
```
5ï¸âƒ£ Valutare un modello via Gemini (API) â€“ modalitÃ  TOP-K:

```bash
export GOOGLE_API_KEY="AIza-xxxxxxxx"
python prompting/evaluate_GEMINI_topk.py --sessions output/cowrie_TEST.jsonl --k 5 --n 200 --model gemini-1.5-flash-latest
```
6ï¸âƒ£ Valutare un modello via Gemini (API) + RAG:
```bash
python prompting/evaluate_GEMINI_RAG.py --sessions output/cowrie_TEST.jsonl --index-file output/cowrie_TRAIN.jsonl --k 5 --rag-k 3 --context-len 5 --n 200 --model gemini-1.5-flash-latest
```
â¸»

## ğŸ“Š Output di esempio

Esempio di riga in ollama_results.jsonl:
```bash
{"context": ["whoami", "uname -a"], "expected": "cat /etc/passwd", "predicted": "cat /etc/shadow", "similarity": 0.85, "match": 0, "raw_response": "cat /etc/shadow"}
```
Esempio di file summary.json:
```bash
{
  "total_new": 200,
  "exact_acc": 0.12,
  "near_matches_jaccard>=0.80": 0.35,
  "error_rate": 0.05,
  "model": "mistral:7b-instruct-q4_0",
  "generated_at": "2025-11-04T10:00:00Z"
}
```

â¸»

---

## ğŸ§  Note metodologiche

- I modelli funzionano meglio con **prompt brevi** e **in inglese**, come quelli costruiti in  
  `core_topk.py` e `core_RAG.py`.
- Le predizioni devono sempre essere pulite: estrarre **solo la prima riga valida**, usando le funzioni
  di parsing e normalizzazione in `utils.py`.
- Testare diversi valori di **context length** (`--context-len`), soprattutto con:  
  - `evaluate_ollama_topk.py`  
  - `evaluate_GEMINI_topk.py`  
  - `evaluate_ollama_RAG.py`  
  - `evaluate_GEMINI_RAG.py`
- Per valutare correttamente i modelli, utilizzare sia:
  - **Exact Match** (giÃ  implementato nel tuo codice)
  - **Confronto normalizzato** tramite `utils.normalize_for_compare()`
- Quando si usano API come Gemini, mantenere attivo **rate limit** + **sleep** (giÃ  presente nei tuoi script).
- Preferire modelli locali via **Ollama** (`codellama`, `llama3`, `mistral`, `gemma:2b`) per test massivi,
  perchÃ© gli script `evaluate_ollama_*` sono ottimizzati per esecuzioni lunghe.
- Usare dataset puliti generati da:
  - `merge_cowrie_datasets.py`
  - `analyze_and_clean.py`
  - `convert_sessions_to_finetune.py`  
  per ridurre rumore e comandi non utili allâ€™LLM.
- Per RAG, evitare di reinizializzare il DB: `VectorContextRetriever` verifica giÃ  se la collezione esiste.

---

## ğŸ”§ Possibili estensioni future

- Addestrare un modello locale tramite **fine-tuning** su `convert_sessions_to_finetune.py`
  (formato giÃ  pronto per supervised next-command prediction).
- Implementare metriche avanzate come:
  - **Top-k Accuracy**
  - **Recall@k**
  - **Confidence Distribution** dei candidati prodotti dal modello
- Integrare direttamente il motore predittivo (top-k o RAG) dentro Cowrie tramite:
  - hook sugli eventi `cowrie.command.input`  
  - API locale che richiama `evaluate_ollama_topk.py`
- Utilizzare `core_RAG.py` per creare un **Honeypot con memoria storica** degli attacchi,
  aggiornando dinamicamente ChromaDB con nuove sessioni.
- Aggiungere una pipeline di:
  - **Command Semantics Classification** per etichettare automaticamente i pattern:
    ricognizione, file exfiltration, credential harvesting, persistence, ecc.
- Costruire dashboard real-time usando i file JSONL prodotti da:
  - `evaluate_ollama_topk.py`
  - `evaluate_ollama_RAG.py`
  - `evaluate_GEMINI_RAG.py`
- Estendere il dataset includendo altri dataset pubblici (Zenodo 3759652, SIHD, HoneySELK)
  giÃ  compatibili con i tuoi script di merge e normalizzazione.

---

## ğŸ“š Riferimenti

- ğŸ **Cowrie Honeypot** â†’ https://github.com/cowrie/cowrie
- ğŸª¤ **Canarytokens** â†’ https://canarytokens.org / https://github.com/thinkst/canarytokens
- ğŸ’» **Ollama** â†’ https://ollama.com / https://github.com/ollama/ollama
- ğŸŒ **OpenRouter API** â†’ https://openrouter.ai
- ğŸ§ª **CyberLab Honeynet Dataset (Zenodo)** â†’ https://zenodo.org/records/3687527
- ğŸ¼ **PANDAcap SSH Dataset** â†’ https://zenodo.org/records/3759652
- ğŸ­ **SIHD â€“ Smart Industrial Honeypot Dataset (IEEE)** â†’ https://ieee-dataport.org/documents/sihd-smart-industrial-honeypot-dataset
- ğŸ•µï¸ **HoneySELK Cyber Attacks Dataset (IEEE)** â†’ https://ieee-dataport.org/open-access/dataset-cyber-attacks-honeyselk

### ğŸ“˜ Key Papers
- ğŸ“„ Nawrocki et al. (2016) â€” "A Survey on Honeypot Software and Data Analysis"  
- ğŸ¤– Deng et al. (2023) â€” "PentestGPT: Evaluating LLMs for Automated Penetration Testing"  
- ğŸ›¡ï¸ Alata et al. â€” "Lessons Learned from High-Interaction Honeypot Deployment"  
- ğŸ¦ Whitham â€” "Canary Tokens and Deception"  

---

## ğŸ‘¥ Autori

| | | |
|:--:|:--:|:--:|
| <a href="https://github.com/BlackRaffo70"><img src="https://github.com/BlackRaffo70.png" width="110" alt="avatar Raffaele Neri"></a> | <a href="https://github.com/melomatte"><img src="https://github.com/melomatte.png" width="110" alt="avatar Matteo Melotti"></a> | <a href="https://github.com/kikeeeee"><img src="https://github.com/kikeeeee.png" width="110" alt="avatar Enrico Borsetti"></a> |
| **Raffaele Neri**<br/>[@BlackRaffo70](https://github.com/BlackRaffo70) | **Matteo Melotti**<br/>[@melottimatteo](https://github.com/melomatte) | **Enrico Borsetti**<br/>[@enricoborsetti](https://github.com/kikeeeee) |

---

ğŸ“˜ *Progetto di ricerca:*  
**ğŸ¯ Predictive Deception â€“ LLM-based Command Anticipation in SSH Honeypots**  
UniversitÃ  di Bologna â€“ Corso di Laurea Magistrale in Ingegneria Informatica  

ğŸ‘¨â€ğŸ« *Docente referente:* **Prof. Michele Colajanni**
