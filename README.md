<img width="1024" height="233" alt="image" src="https://github.com/user-attachments/assets/e210dcce-57f2-4470-a895-780896dbe45f" />

# ğŸ¯ Predictive Deception â€” LLM-based Command Anticipation in SSH Honeypots

---

## ğŸ¯ Obiettivo del progetto â€” *Predictive Deception per Honeypot*

Gli honeypot tradizionali osservano e registrano ciÃ² che lâ€™attaccante fa **solo dopo** lâ€™esecuzione di un comando.  
Questo progetto introduce un nuovo paradigma: sfruttare un **LLM** per trasformare lâ€™honeypot da sistema passivo a **sistema predittivo e adattivo**.

---

## ğŸš€ Idea chiave  
Un modello di linguaggio (CodeLlama, Llama 3, Gemini, Mistral) analizza in tempo reale la sequenza dei comandi dellâ€™attaccante e **predice il prossimo comando** con elevata accuratezza â€” *prima che venga digitato*.

Questa predizione permette al sistema di costruire sul filesystem una *realtÃ  manipolata* che lâ€™attaccante non puÃ² distinguere da quella autentica.

---

## ğŸª¤ Core Concept: Predictive Deception

La **deception** in questo progetto non Ã¨ statica, ma *dinamica e reattiva*.  
Si basa su tre principi fondamentali:

### 1ï¸âƒ£ *Preparazione anticipata*  
Prima che lâ€™attaccante esegua il comando previsto, il sistema crea:

- file fake ma plausibili  
- directory esca  
- script o configurazioni manipolate  
- log fittizi  
- output alterati

Il tutto generato automaticamente dal modello LLM, a seconda del comando predetto.

Esempio:  
se il modello predice `cat /etc/passwd`, il sistema puÃ² generare una versione *decoy*, coerente ma falsificata.

---

### 2ï¸âƒ£ *Branching e pruning*  
Per ogni comando vengono predetti **5 possibili next-steps**.

Per ciascuno viene generata una *branch* di deception:

- branch A â†’ file X  
- branch B â†’ directory Y  
- branch C â†’ canary token Z  
- â€¦

Quando lâ€™attaccante esegue realmente un comando, il sistema:

- mantiene **solo la branch corretta**  
- elimina le altre 4 con cleanup automatico  
- conserva coerenza assoluta nel filesystem

Questo crea la sensazione di un sistema vivo e coerente, impossibile da sgamare.

---

### 3ï¸âƒ£ *Deception adattiva basata su RAG*  
L'LLM non predice "a caso".  
Combina:

- history della sessione  
- sequenze di attacchi precedenti conservate via **ChromaDB RAG**

In questo modo la deception diventa *personalizzata*:

- se lâ€™attaccante mostra pattern simili a botnet â†’ deception tecnica  
- se mostra pattern umani â†’ deception narrativa e coerente  
- se usa tool come Mirai, Tsunami, zmap â†’ deception su file system e servizi

---

## ğŸ” PerchÃ© Ã¨ rivoluzionario

- ğŸª¤ **Deception mirata e contestuale**  
  Non Ã¨ la solita deception statica: il sistema modifica lâ€™ambiente *in tempo reale* in base al comportamento.

- ğŸ¯ **Trigger nascosti intelligenti**  
  Canary tokens, honey-credentials e file monitoring attivati solo quando utili.

- ğŸ§  **Ingaggio dellâ€™attaccante aumentato**  
  Lâ€™ambiente sembra perfettamente reale, con struttura coerente e reattiva.

- ğŸ“¡ **Threat intelligence potenziata**  
  La correlazione via RAG tra comandi vecchi e nuovi permette un profiling comportamentale avanzato.

- ğŸ› **Riduzione dei falsi positivi**  
  La predizione contestuale evita di generare deception non rilevanti.

---

## ğŸ§© In sintesi  
Il progetto trasforma lâ€™honeypot in un sistema **proattivo**, capace non solo di osservare ma di:

- **anticipare** lâ€™attaccante  
- **modellare** lâ€™ambiente in base al suo comportamento  
- **manipolare** la percezione dellâ€™host  
- **studiare** tecniche emergenti tramite dataset predittivi

Si passa cosÃ¬ da un honeypot statico a un sistema **intelligente, adattivo e realmente interattivo**, in grado di raccogliere informazioni impossibili da ottenere con soluzioni tradizionali.

---

## ğŸ“¦ Requirements

Il progetto utilizza LLM, RAG e dataset da honeypot (Cowrie) per analisi predittiva, deception adattiva e fine-tuning dei modelli.  
Di seguito lâ€™elenco completo e organizzato delle dipendenze necessarie.

---

## ğŸ”§ Core Dependencies
Librerie principali per gestione ambiente, logging, preprocessing e networking.

- `python-dotenv` â€” gestione variabili dâ€™ambiente
- `tqdm` â€” progress bar e logging
- `requests` â€” API e download dataset
- `jsonlines` â€” lettura/scrittura JSONL
- `pandas` â€” preprocess e analisi dataset

---

## ğŸ§  RAG & Embeddings  
Moduli necessari per creare e interrogare il database vettoriale basato su ChromaDB.

- `chromadb`
- `sentence-transformers`  
  (utilizzato per MiniLM-L6-v2 nei retrieval)

---

## ğŸ¤– LLM APIs (Gemini / OpenAI / HF)
Integrazione con i principali modelli LLM utilizzati nel progetto per predizione e generazione degli artefatti di deception.

- `openai`
- `google-genai`
- `transformers`
- `tokenizers`
- `safetensors`

---

## ğŸ§ª Fine-Tuning (CodeLlama / LoRA / PEFT)
Dipendenze necessarie per addestramento leggero (LoRA) su dataset Cowrie + sequenze attaccante.

- `torch`
- `accelerate`
- `datasets`
- `peft`
- `bitsandbytes`  
  (quantizzazione 4/8-bit per GPU poco potenti)

---

## ğŸ“Š Machine Learning Utilities
Strumenti usati per normalizzazione, feature engineering, clustering comportamentale.

- `scikit-learn`
- `numpy`

---

## ğŸ” Nota
Tutte le librerie sono compatibili con Python **3.10+** e con ambienti virtuali standard (`venv`/`conda`).  
Per lâ€™ecosistema LLM Ã¨ consigliata una GPU NVIDIA con supporto CUDA, ma il sistema funziona anche in CPU per test, predizione e RAG.

## ğŸ“ Struttura del repository

```bash
Predictive_deception/
â”‚
â”œâ”€â”€ chroma_storage/                     # Database vettoriale ChromaDB
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ DB_checkpoint.txt
â”‚
â”œâ”€â”€ deception/                          # Motore di deception + defender runtime
â”‚   â”œâ”€â”€ scenarios/
â”‚   â”œâ”€â”€ brain.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ defender.py
â”‚   â”œâ”€â”€ host.key
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ session_handler.py
â”‚   â””â”€â”€ ssh_server.py
â”‚
â”œâ”€â”€ Honeypot/                           # Ambiente honeypot (Vagrant + Ansible)
â”‚   â”œâ”€â”€ Vagrantfile
â”‚   â”œâ”€â”€ playbook.yml
â”‚   â”œâ”€â”€ readme.txt
â”‚   â””â”€â”€ roles/
â”‚       â”œâ”€â”€ db_vettoriale/
â”‚       â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ defender/
â”‚       â”‚   â”œâ”€â”€ files/
â”‚       â”‚   â”‚   â””â”€â”€ defender2.py
â”‚       â”‚   â”œâ”€â”€ tasks/
â”‚       â”‚   â””â”€â”€ vars/
â”‚       â”œâ”€â”€ env_python/
â”‚       â”‚   â”œâ”€â”€ tasks/
â”‚       â”‚   â””â”€â”€ vars/
â”‚       â””â”€â”€ fakeshell_v2/
â”‚           â”œâ”€â”€ files/
â”‚           â”‚   â”œâ”€â”€ fakeshell.py
â”‚           â”‚   â””â”€â”€ fakeshell_easy.py
â”‚           â”œâ”€â”€ handlers/
â”‚           â””â”€â”€ tasks/
â”‚
â”œâ”€â”€ inspectDataset/                     # Analisi e pulizia dataset Cowrie
â”‚   â”œâ”€â”€ analyze_and_clean.py
â”‚   â”œâ”€â”€ download_zenodo.py
â”‚   â””â”€â”€ merge_cowrie_datasets.py
â”‚
â”œâ”€â”€ prompting/                          # Motore predittivo LLM
â”‚   â”œâ”€â”€ core_rag.py
â”‚   â”œâ”€â”€ core_topk.py
â”‚   â”œâ”€â”€ evaluate_gemini_rag.py
â”‚   â”œâ”€â”€ evaluate_gemini_topk.py
â”‚   â”œâ”€â”€ evaluate_ollama_rag.py
â”‚   â”œâ”€â”€ evaluate_ollama_topk.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

â¸»
---
## ğŸ§­ Workflow del progetto (script principali)

| Step | Script / File                                                | Input                               | Output                                      | Descrizione |
|------|--------------------------------------------------------------|-------------------------------------|---------------------------------------------|-------------|
| 1ï¸âƒ£  | `inspectDataset/download_zenodo.py`                          | â€”                                   | `data/*.tar.gz`, `data/*.json`              | Scarica automaticamente i dataset Cowrie da Zenodo e li salva nella cartella dati locale. |
| 2ï¸âƒ£  | `inspectDataset/analyze_and_clean.py`                        | `data/*.json`                       | `*_RAW.jsonl`, `*_CLEAN.jsonl`, statistiche | Analizza i log Cowrie, normalizza i comandi, pulisce rumore/duplicati e produce versioni RAW/CLEAN in JSONL. |
| 3ï¸âƒ£  | `inspectDataset/merge_cowrie_datasets.py`                    | `*_CLEAN.jsonl`                     | `cowrie_ALL_*.jsonl`, `cowrie_TRAIN/TEST`   | Unisce piÃ¹ file puliti, crea un dataset unico e lo split train/test per gli esperimenti. |
| 4ï¸âƒ£  | `prompting/core_rag.py`                                      | `cowrie_TRAIN.jsonl`, `chroma_storage/` | `chroma_storage/*`                          | Costruisce e interroga il database vettoriale ChromaDB (embedding + retrieval) per il RAG. |
| 5ï¸âƒ£  | `prompting/core_topk.py`                                     | Sessioni JSONL                      | â€”                                           | Motore generico di predizione Top-k (senza RAG), riusato dai vari script di valutazione. |
| 6ï¸âƒ£  | `prompting/evaluate_gemini_topk.py`                          | `cowrie_TEST.jsonl`                | `output/gemini_topk_results.jsonl`          | Valuta lâ€™API Gemini in modalitÃ  Top-k, misurando Top-1/Top-5 sulle sessioni di test. |
| 7ï¸âƒ£  | `prompting/evaluate_gemini_rag.py`                           | `cowrie_TEST.jsonl`, `chroma_storage/` | `output/gemini_rag_results.jsonl`       | Valuta Gemini integrato con RAG (ChromaDB), usando contesto + retrieval per predire il prossimo comando. |
| 8ï¸âƒ£  | `prompting/evaluate_ollama_topk.py`                          | `cowrie_TEST.jsonl`                | `output/ollama_topk_results.jsonl`          | Valuta modelli locali (es. CodeLlama via Ollama) in modalitÃ  Top-k senza RAG. |
| 9ï¸âƒ£  | `prompting/evaluate_ollama_rag.py`                           | `cowrie_TEST.jsonl`, `chroma_storage/` | `output/ollama_rag_results.jsonl`       | Valuta modelli locali con RAG (vector search + LLM) sulle stesse sessioni di test. |
| ğŸ”Ÿ  | `Honeypot/Vagrantfile` + `Honeypot/playbook.yml`              | â€”                                   | VM di test configurata                      | Crea lâ€™ambiente honeypot con Vagrant + Ansible (rete, pacchetti, utenti, Python, log, ecc.). |
| 1ï¸âƒ£1ï¸âƒ£ | `Honeypot/roles/fakeshell_v2/files/fakeshell.py`             | Input interattivo SSH nella VM      | `/var/log/fakeshell.json`                   | Fake shell avanzata: esegue comandi reali, mostra prompt realistico e logga ogni comando in formato JSONL. |
| 1ï¸âƒ£2ï¸âƒ£ | `Honeypot/roles/defender/files/defender2.py`                 | `/var/log/fakeshell.json`, ChromaDB | File di deception nel FS della VM           | Versione deployabile del Defender: segue il log, usa RAG+Gemini per predire i prossimi comandi e crea artefatti di deception. |
| 1ï¸âƒ£3ï¸âƒ£ | `deception/main.py` + `deception/ssh_server.py` + `session_handler.py` | Connessioni SSH reali               | Sessioni honeypot instradate verso il â€œbrainâ€ | Avvia il server SSH honeypot, accetta connessioni, gestisce le sessioni e inoltra i comandi al motore di deception. |
| 1ï¸âƒ£4ï¸âƒ£ | `deception/defender.py`                                      | Log honeypot (es. `fakeshell.json`), ChromaDB, LLM | Artefatti reali + log difese      | Defender runtime principale: legge i comandi in tempo reale, predice i prossimi passi con RAG+LLM e crea file/configurazioni esca. |
| 1ï¸âƒ£5ï¸âƒ£ | `deception/brain.py`                                         | Stato sessioni + log + predizioni   | Decisioni di deception / strategie           | Coordina a livello alto la strategia di deception (scenari, livelli di ingaggio, tipo di artefatti da generare). |
| 1ï¸âƒ£6ï¸âƒ£ | `deception/config.py`                                        | â€”                                   | Parametri di configurazione condivisi        | Centralizza porte, path, chiavi API, location del log, del DB vettoriale e degli scenari di deception. |
---


## ğŸ§  Note metodologiche

- I modelli lavorano meglio con **prompt compatti** e **in inglese**, come quelli costruiti in  
  `prompting/core_topk.py` e `prompting/core_rag.py`.

- Le predizioni vanno sempre **pulite e normalizzate**:  
  usa le funzioni di parsing e confronto in `prompting/utils.py`  
  (es. normalizzazione comandi, split per riga, gestione spazi).

- Ãˆ utile testare diversi valori di **context length** (`CONTEXT_LEN`), in particolare con:
  - `prompting/evaluate_gemini_topk.py`
  - `prompting/evaluate_gemini_rag.py`
  - `prompting/evaluate_ollama_topk.py`
  - `prompting/evaluate_ollama_rag.py`
  - e nel runtime del defender (`deception/defender.py`), dove `CONTEXT_LEN` controlla quanto â€œpassatoâ€ vede il modello.

- Per valutare correttamente i modelli conviene combinare:
  - **Exact Match** (giÃ  calcolato negli script di valutazione)
  - **Confronto normalizzato**, usando le utility di `prompting/utils.py`
    per ridurre lâ€™effetto di differenze minori (spazi, quote, ecc.).

- Quando usi API esterne come **Gemini** (`evaluate_gemini_*.py`, `deception/defender.py`):
  - tieni conto di **rate limit** e possibili errori temporanei;
  - mantieni una logica di retry/sleep leggera, cosÃ¬ da non bloccare gli esperimenti o il defender.

- Per esperimenti su larga scala Ã¨ preferibile usare modelli locali via **Ollama**:
  - `prompting/evaluate_ollama_topk.py`
  - `prompting/evaluate_ollama_rag.py`  
  sono pensati per girare a lungo, con loop su centinaia/migliaia di sessioni.

- Usa sempre dataset **puliti e coerenti**, generati dalla pipeline:
  - `inspectDataset/download_zenodo.py` â†’ download dei log Cowrie
  - `inspectDataset/analyze_and_clean.py` â†’ pulizia, normalizzazione e statistiche
  - `inspectDataset/merge_cowrie_datasets.py` â†’ merge e split train/test  
  in modo da ridurre rumore, comandi rari inutili e formati incoerenti.

- Per il **RAG**:
  - indicizza una sola volta in `chroma_storage/` usando la logica di `prompting/core_rag.py`;
  - riutilizza lo stesso DB vettoriale sia negli script di valutazione (`evaluate_*_rag.py`)  
    sia nel defender (`deception/defender.py`) tramite `VectorContextRetriever`;
  - evita di ricreare la collection a ogni esecuzione: il retriever Ã¨ giÃ  pensato per lavorare su un DB esistente.
---

## ğŸ”§ Possibili estensioni future

- Addestrare un modello locale tramite **fine-tuning** sui dataset puliti generati da  
  `inspectDataset/analyze_and_clean.py` e `inspectDataset/merge_cowrie_datasets.py`  
  (esportando le sessioni in formato inputâ†’next-command per supervised prediction).

- Estendere il set di metriche nelle valutazioni di:
  - `prompting/evaluate_gemini_topk.py`
  - `prompting/evaluate_gemini_rag.py`
  - `prompting/evaluate_ollama_topk.py`
  - `prompting/evaluate_ollama_rag.py`  
  includendo, oltre alla Top-k Accuracy:
  - **Recall@k**
  - distribuzione di confidenza / ranking dei candidati (es. punteggi normalizzati).

- Integrare in modo ancora piÃ¹ stretto il motore predittivo nel flusso dellâ€™honeypot:
  - richiamare la logica di `prompting/core_topk.py` o `prompting/core_rag.py`  
    direttamente da `deception/session_handler.py` o `deception/ssh_server.py`;
  - orchestrare le risposte di deception tramite `deception/brain.py` e `deception/defender.py`
    per adattare gli artefatti al profilo dellâ€™attaccante.

- Usare `prompting/core_rag.py` insieme al DB in `chroma_storage/` per costruire  
  un **honeypot con memoria storica**:
  - aggiornare periodicamente ChromaDB con nuove sessioni acquisite dallâ€™ambiente Vagrant (`Honeypot/`);
  - permettere al defender (`deception/defender.py`) di sfruttare anche gli attacchi piÃ¹ recenti.

- Aggiungere una pipeline di **Command Semantics Classification** nel motore di prompting:
  - estendere `prompting/utils.py` con etichette di classe (ricognizione, lateral movement, credential harvesting, persistence, ecc.);
  - usare queste etichette in `deception/brain.py` per scegliere strategie di deception diverse per ogni tipologia di comando.

- Costruire dashboard real-time a partire dai log JSONL prodotti da:
  - honeypot fake shell (`/var/log/fakeshell.json`, generato da `fakeshell.py` / `fakeshell_easy.py` in `Honeypot/roles/fakeshell_v2/files/`);
  - output del defender (`output_deception/runtime/*.json` gestiti da `deception/defender.py`);
  - risultati sperimentali in JSONL generati dagli script di valutazione nella cartella `prompting/`.  
  Questi possono essere visualizzati con stack tipo ELK/Grafana.

- Estendere il dataset includendo altri sorgenti pubblici (es. nuovi dump Cowrie o honeypot simili)  
  e normalizzarli tramite:
  - `inspectDataset/download_zenodo.py` (per download automatici),
  - `inspectDataset/analyze_and_clean.py`,
  - `inspectDataset/merge_cowrie_datasets.py`,  
  mantenendo un formato uniforme per addestramento, RAG e valutazione.
---

## ğŸ“š Riferimenti

- ğŸ **Cowrie Honeypot** â†’ https://github.com/cowrie/cowrie
- ğŸª¤ **Canarytokens** â†’ https://canarytokens.org / https://github.com/thinkst/canarytokens
- ğŸ’» **Ollama** â†’ https://ollama.com / https://github.com/ollama/ollama
- ğŸŒ **OpenRouter API** â†’ https://openrouter.ai
- ğŸ§ª **CyberLab Honeynet Dataset (Zenodo)** â†’ https://zenodo.org/records/3687527
- ğŸ¼ **PANDAcap SSH Dataset** â†’ https://zenodo.org/records/3759652
- ğŸ­ **SIHD â€“ Smart Industrial Honeypot Dataset (IEEE)** â†’ https://ieee-dataport.org/documents/sihd-smart-industrial-honeypot-dataset
- ğŸ•µï¸ **HoneySELK Cyber Attacks Dataset (IEEE)** â†’ https://ieee-dataport.org/open-access/dataset-cyber-attacks-honeyselk

### ğŸ“˜ Key Papers
- ğŸ“„ Nawrocki et al. (2016) â€” "A Survey on Honeypot Software and Data Analysis"  
- ğŸ¤– Deng et al. (2023) â€” "PentestGPT: Evaluating LLMs for Automated Penetration Testing"  
- ğŸ›¡ï¸ Alata et al. â€” "Lessons Learned from High-Interaction Honeypot Deployment"  
- ğŸ¦ Whitham â€” "Canary Tokens and Deception"  

---

## ğŸ‘¥ Autori

| | | |
|:--:|:--:|:--:|
| <a href="https://github.com/BlackRaffo70"><img src="https://github.com/BlackRaffo70.png" width="110" alt="avatar Raffaele Neri"></a> | <a href="https://github.com/melomatte"><img src="https://github.com/melomatte.png" width="110" alt="avatar Matteo Melotti"></a> | <a href="https://github.com/kikeeeee"><img src="https://github.com/kikeeeee.png" width="110" alt="avatar Enrico Borsetti"></a> |
| **Raffaele Neri**<br/>[@BlackRaffo70](https://github.com/BlackRaffo70) | **Matteo Melotti**<br/>[@melottimatteo](https://github.com/melomatte) | **Enrico Borsetti**<br/>[@enricoborsetti](https://github.com/kikeeeee) |

---

ğŸ“˜ *Progetto di ricerca:*  
**ğŸ¯ Predictive Deception â€“ LLM-based Command Anticipation in SSH Honeypots**  
UniversitÃ  di Bologna â€“ Corso di Laurea Magistrale in Ingegneria Informatica  

ğŸ‘¨â€ğŸ« *Docente referente:* **Prof. Michele Colajanni**
