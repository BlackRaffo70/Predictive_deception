<img width="1024" height="233" alt="image" src="https://github.com/user-attachments/assets/e210dcce-57f2-4470-a895-780896dbe45f" />

# ğŸ¯ Predictive Deception â€” LLM-based Command Anticipation in SSH Honeypots

---
## ğŸ¯ Obiettivo del progetto: *Predictive Deception per Honeypot*

Gli honeypot tradizionali osservano e registrano ciÃ² che lâ€™attaccante fa **solo dopo** che un comando Ã¨ stato eseguito.  
Il nostro progetto introduce un cambio di paradigma: usare un **LLM** per trasformare lâ€™honeypot da sistema reattivo a **sistema predittivo**.

### ğŸš€ Idea chiave  
Un modello di linguaggio (es. CodeLlama o Gemini) analizza in tempo reale la sequenza di comandi digitati dallâ€™attaccante e **predice il prossimo comando probabile** prima che venga effettivamente eseguito.

### ğŸ” PerchÃ© Ã¨ rivoluzionario  
Questa capacitÃ  permette allâ€™honeypot di:

- ğŸª¤ **Preparare deception mirate in anticipo**  
  Creare file fake, configurazioni fittizie, directory esca o output manipolati **prima** che lâ€™attaccante le richieda.

- ğŸ¯ **Attivare trigger intelligenti e invisibili**  
  Canary tokens, log ad alta granularitÃ , honey-credentials, environment spoofing, tutto avviato *appena* la predizione indica un probabile step successivo.

- ğŸ§  **Aumentare lâ€™ingaggio dellâ€™attaccante**  
  Simulare sistemi realistici, far credere allâ€™attaccante di essere nel posto giusto e catturare operazioni piÃ¹ avanzate.

- ğŸ“ˆ **Migliorare la qualitÃ  dellâ€™intelligence**  
  Comprendere pattern, automatizzare il profiling di tool e campagne, generare dataset per threat research.

### ğŸ§© In sintesi  
Il progetto converte lâ€™honeypot in un sistema attivo, capace di **anticipare** il comportamento dellâ€™attaccante e adattarsi, invece di limitarsi a loggare passivamente quello che accade.


---

## ğŸ“¦ Requirements

Il progetto utilizza LLM, RAG e dataset generati da honeypot Cowrie.  
Questi sono i requisiti minimi e completi per eseguire preprocessing, predizione e fine-tuning.

### ğŸ”§ Core Dependencies
- `python-dotenv`
- `tqdm`
- `requests`
- `jsonlines`
- `pandas`

### ğŸ§  RAG & Embeddings
- `chromadb`
- `sentence-transformers`

### ğŸ¤– LLM APIs (Gemini / OpenAI / HF)
- `openai`
- `google-genai`
- `transformers`
- `tokenizers`
- `safetensors`

### ğŸ§ª Fine-Tuning (CodeLlama / PEFT)
- `torch`
- `accelerate`
- `datasets`
- `peft`
- `bitsandbytes`

### ğŸ“Š Machine Learning Utilities
- `scikit-learn`
- `numpy`

---

## ğŸ“ Struttura del repository
```bash
## ğŸ“ Struttura del repository

```bash
Predictive_deception/
â”‚
â”œâ”€â”€ chroma_storage/                     # Storage locale per ChromaDB (RAG)
â”‚
â”œâ”€â”€ data/                               # Dataset Cowrie grezzi o scaricati
â”‚
â”œâ”€â”€ fine_tuning/                        # Script per preparazione e training modelli
â”‚   â””â”€â”€ convert_sessions_to_finetune.py # Converte sessioni SSH in dataset per LLM
â”‚
â”œâ”€â”€ google-cloud-sdk/                   # SDK Google (opzionale, per storage/compute)
â”‚
â”œâ”€â”€ inspectDataset/                     # Analisi e pulizia dataset Cowrie
â”‚   â”œâ”€â”€ analyze_and_clean.py            # Pulizia e normalizzazione eventi
â”‚   â””â”€â”€ merge_cowrie_datasets.py        # Merge file Cowrie multipli
â”‚
â”œâ”€â”€ output/                             # File prodotti dal progetto (dataset, risultati)
â”‚
â”œâ”€â”€ prompting/                          # Modulo per valutazione predittiva LLM
â”‚   â”œâ”€â”€ core_RAG.py                     # Motore RAG locale
â”‚   â”œâ”€â”€ core_topk.py                    # Motore top-k senza RAG
â”‚   â”œâ”€â”€ evaluate_GEMINI_RAG.py          # Valutazione Gemini con RAG
â”‚   â”œâ”€â”€ evaluate_GEMINI_topk.py         # Valutazione Gemini top-k
â”‚   â”œâ”€â”€ evaluate_ollama_RAG.py          # Valutazione modelli locali (Ollama) con RAG
â”‚   â”œâ”€â”€ evaluate_ollama_topk.py         # Valutazione Ollama top-k
â”‚   â””â”€â”€ utils.py                        # Funzioni condivise (tokenizzazione, parsing, ecc.)
â”‚
â”œâ”€â”€ utilities_script/                   # Script di utilitÃ  e preprocessing
â”‚   â”œâ”€â”€ download_zenodo.py              # Download dataset pubblici da Zenodo
â”‚   â”œâ”€â”€ inspect_cowrie_json.py          # Ispezione JSON Cowrie per debugging
â”‚   â””â”€â”€ vector_research.py              # Analisi vettori, embedding e RAG debugging
â”‚
â”œâ”€â”€ venv/                               # Ambiente virtuale Python (non va pushato)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ google-cloud-cli-darwin-x86_64.tar.gz
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ todo.txt


```

â¸»
---

## ğŸ§­ Workflow del progetto

| Step | Script | Input | Output | Descrizione |
|------|--------|--------|---------|-------------|
| 1ï¸âƒ£ | `download_zenodo.py` | â€” | `data/*.json` | Scarica dataset Cowrie da Zenodo (se non presenti) |
| 2ï¸âƒ£ | `inspect_cowrie_json.py` | `data/*.json` | â€” | Ispeziona struttura JSON grezza (debug) |
| 3ï¸âƒ£ | `merge_cowrie_datasets.py` | `data/*.json` | `output/merged_cowrie.jsonl` | Unisce piÃ¹ dataset Cowrie in un unico file |
| 4ï¸âƒ£ | `analyze_and_clean.py` | `output/merged_cowrie.jsonl` | `output/cowrie_sessions.jsonl` | Estrae sessioni, comandi e normalizza i dati |
| 5ï¸âƒ£ | `vector_research.py` | `output/cowrie_TEST.jsonl` | embedding temporanei | Analisi vettori & test embedding (debug RAG) |
| 6ï¸âƒ£ | `convert_sessions_to_finetune.py` | `output/cowrie_sessions.jsonl` | `output/predictive_pairs.jsonl` | Crea coppie (context â†’ next) per training LL |
| 7ï¸âƒ£ | `core_topk.py` | `output/predictive_pairs.jsonl` | predizioni interne | Motore predittivo baseline top-k |
| 8ï¸âƒ£ | `core_RAG.py` | `output/predictive_pairs.jsonl` + ChromaDB | predizioni RAG | Motore predittivo con Retrieval-Augmented |
| 9ï¸âƒ£ | `evaluate_ollama_topk.py` | `output/predictive_pairs.jsonl` | `output/ollama_topk_results.jsonl` | Valuta modelli Ollama (solo top-k) |
| ğŸ”Ÿ | `evaluate_ollama_RAG.py` | `output/predictive_pairs.jsonl` | `output/ollama_rag_results.jsonl` | Valuta Ollama con RAG |
| 1ï¸âƒ£1ï¸âƒ£ | `evaluate_GEMINI_topk.py` | `output/predictive_pairs.jsonl` | `output/gemini_topk_results.jsonl` | Valuta Gemini API (top-k) |
| 1ï¸âƒ£2ï¸âƒ£ | `evaluate_GEMINI_RAG.py` | `output/predictive_pairs.jsonl` + ChromaDB | `output/gemini_rag_results.jsonl` | Valuta Gemini con RAG |
| 1ï¸âƒ£3ï¸âƒ£ | `utils.py` | â€” | â€” | Funzioni condivise (tokenizer, parsing, formatting) |


â¸»

## ğŸš€ **Esempi di utilizzo rapido**

1ï¸âƒ£ Analisi dataset Cowrie:
```bash
python analyze_cowrie_dataset.py --input data/cowrie_2020-02-29.json --output output/cowrie
```
2ï¸âƒ£ Merge & Clean dei dataset Cowrie
```bash
python build_predictive_pairs.py --input output/cowrie_sessions.jsonl --output output/predictive_pairs.jsonl --context-len 1
```
3ï¸âƒ£ Valutare modello locale con Ollama + RAG(opzionale):

```bash
ollama pull mistral:7b-instruct-q4_0
ollama serve &
python evaluate_ollama_topk.py --data output/predictive_pairs.jsonl --model mistral:7b-instruct-q4_0 --n 200 --temp 0.1
```
4ï¸âƒ£ Valutare modello via Gemini (API):

```bash
export OPENROUTER_API_KEY="sk-or-xxxxxxxx"
python evaluate_LLM_OpenRouter.py --input output/predictive_pairs.jsonl --model deepseek/deepseek-r1:free --n 200
```

â¸»

## ğŸ“Š Output di esempio

Esempio di riga in ollama_results.jsonl:
```bash
{"context": ["whoami", "uname -a"], "expected": "cat /etc/passwd", "predicted": "cat /etc/shadow", "similarity": 0.85, "match": 0, "raw_response": "cat /etc/shadow"}
```
Esempio di file summary.json:
```bash
{
  "total_new": 200,
  "exact_acc": 0.12,
  "near_matches_jaccard>=0.80": 0.35,
  "error_rate": 0.05,
  "model": "mistral:7b-instruct-q4_0",
  "generated_at": "2025-11-04T10:00:00Z"
}
```

â¸»

---

## ğŸ§  Note metodologiche

- Prompt **brevi** e in **inglese** migliorano la precisione del modello.  
- Estrarre **solo la prima riga valida** del comando previsto.  
- Testare diversi valori di **context length** (es. 1â€“5 comandi precedenti).  
- Misurare sia **Exact Match** che **similaritÃ  testuale** (Jaccard / SequenceMatcher).  
- Implementare **rate-limit** e **backoff** per lâ€™uso di API gratuite.  
- Preferire **Ollama locale** o **GPU universitaria** per batch lunghi di test.  

---

## ğŸ”§ Possibili estensioni future

- Fine-tuning su dataset SSH per migliorare la **precisione predittiva**.  
- Introduzione di **Top-k accuracy** (predizione di piÃ¹ comandi candidati).  
- Integrazione diretta con sistemi honeypot come **Cowrie** o **CanaryTokens**.  
- Analisi **semantica** dei pattern di attacco (ricognizione, persistence, privilege escalation, ecc.).  

---

## ğŸ“š Riferimenti

- ğŸ **Cowrie Honeypot** â†’ [github.com/cowrie/cowrie](https://github.com/cowrie/cowrie)  
- ğŸª¤ **Canarytokens** â†’ [canarytokens.org](https://canarytokens.org) / [github.com/thinkst/canarytokens](https://github.com/thinkst/canarytokens)  
- ğŸ’» **Ollama** â†’ [ollama.com](https://ollama.com) / [github.com/ollama/ollama](https://github.com/ollama/ollama)  
- ğŸŒ **OpenRouter API** â†’ [openrouter.ai](https://openrouter.ai)  

---

## ğŸ‘¥ Autori

| | | |
|:--:|:--:|:--:|
| <a href="https://github.com/BlackRaffo70"><img src="https://github.com/BlackRaffo70.png" width="110" alt="avatar Raffaele Neri"></a> | <a href="https://github.com/melomatte"><img src="https://github.com/melomatte.png" width="110" alt="avatar Matteo Melotti"></a> | <a href="https://github.com/kikeeeee"><img src="https://github.com/kikeeeee.png" width="110" alt="avatar Enrico Borsetti"></a> |
| **Raffaele Neri**<br/>[@BlackRaffo70](https://github.com/BlackRaffo70) | **Matteo Melotti**<br/>[@melottimatteo](https://github.com/melomatte) | **Enrico Borsetti**<br/>[@enricoborsetti](https://github.com/kikeeeee) |

---

ğŸ“˜ *Progetto di ricerca:*  
**ğŸ¯ Predictive Deception â€“ LLM-based Command Anticipation in SSH Honeypots**  
UniversitÃ  di Bologna â€“ Corso di Laurea Magistrale in Ingegneria Informatica  

ğŸ‘¨â€ğŸ« *Docente referente:* **Prof. Michele Colajanni**
