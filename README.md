<img width="1024" height="233" alt="image" src="https://github.com/user-attachments/assets/e210dcce-57f2-4470-a895-780896dbe45f" />

# ğŸ¯ Predictive Deception â€” LLM-based Command Anticipation in SSH Honeypots

---

## ğŸ¯ Obiettivo del progetto â€” *Predictive Deception per Honeypot*

Gli honeypot tradizionali osservano e registrano ciÃ² che lâ€™attaccante fa **solo dopo** lâ€™esecuzione di un comando.  
Questo progetto introduce un nuovo paradigma: sfruttare un **LLM** per trasformare lâ€™honeypot da sistema passivo a **sistema predittivo e adattivo**.

---

## ğŸš€ Idea chiave  
Un modello di linguaggio (CodeLlama, Llama 3, Gemini, Mistral) analizza in tempo reale la sequenza dei comandi dellâ€™attaccante e **predice il prossimo comando** con elevata accuratezza â€” *prima che venga digitato*.

Questa predizione permette al sistema di costruire sul filesystem una *realtÃ  manipolata* che lâ€™attaccante non deve essere in grado di distinguere da quella autentica.

---

## ğŸª¤ Core Concept: Predictive Deception

La **deception** in questo progetto non Ã¨ statica, ma *dinamica e reattiva*.  
Si basa su tre principi fondamentali:

### 1ï¸âƒ£ *Preparazione anticipata*  
Prima che lâ€™attaccante esegua il comando previsto, il sistema crea:

- file fake ma plausibili  
- directory esca  
- script o configurazioni manipolate  
- log fittizi  
- output alterati

Il tutto generato automaticamente dal modello LLM, a seconda del comando predetto.

Esempio:  
se il modello predice `cat /etc/passwd`, il sistema puÃ² generare una versione *decoy*, coerente ma falsificata.

---

### 2ï¸âƒ£ *Branching e pruning*  
Per ogni comando vengono predetti **5 possibili next-steps**.

Per ciascuno viene generata una *branch* di deception:

- branch A â†’ file X  
- branch B â†’ file Y  
- â€¦

Quando lâ€™attaccante esegue realmente uno dei comandi predetti, il sistema:

- mantiene **solo la branch corretta**  
- elimina le altre 4 con cleanup automatico  
- conserva coerenza assoluta nel filesystem

Questo crea la sensazione di un sistema vivo e coerente, difficilmente roconoscibile.

---

### 3ï¸âƒ£ *Deception adattiva basata su RAG*  
L'LLM non predice "a caso".  
Combina:

- history della sessione  
- sequenze di attacchi precedenti conservate via **ChromaDB RAG**

---

## ğŸ” PerchÃ© Ã¨ rivoluzionario

- ğŸª¤ **Deception mirata e contestuale**  
  Non Ã¨ la solita deception statica: il sistema modifica lâ€™ambiente *in tempo reale* in base al comportamento.

- ğŸ§  **Ingaggio dellâ€™attaccante aumentato**  
  Lâ€™ambiente sembra perfettamente reale, con struttura coerente e reattiva.

- ğŸ› **Riduzione dei falsi positivi**  
  La predizione contestuale evita di generare deception non rilevanti.

---

## ğŸ§© In sintesi  
Il progetto trasforma lâ€™honeypot in un sistema **proattivo**, capace non solo di osservare ma di:

- **anticipare** lâ€™attaccante  
- **modellare** lâ€™ambiente in base al suo comportamento  
- **manipolare** la percezione dellâ€™host
- 
Si passa cosÃ¬ da un honeypot statico a un sistema **intelligente, adattivo e realmente interattivo**, in grado di raccogliere informazioni impossibili da ottenere con soluzioni tradizionali.

---

## ğŸ“¦ Requirements

Il progetto utilizza LLM, RAG e dataset da honeypot (Cowrie) per analisi predittiva, deception adattiva e fine-tuning dei modelli.  
Di seguito lâ€™elenco completo e organizzato delle dipendenze necessarie.

---

## ğŸ”§ Core Dependencies
Librerie principali per gestione ambiente, logging, preprocessing e networking.

- `python-dotenv` â€” gestione variabili dâ€™ambiente
- `tqdm` â€” progress bar e logging
- `requests` â€” API e download dataset
- `jsonlines` â€” lettura/scrittura JSONL
- `pandas` â€” preprocess e analisi dataset

---

## ğŸ§  RAG & Embeddings  
Moduli necessari per creare e interrogare il database vettoriale basato su ChromaDB.

- `chromadb`
- `sentence-transformers`  
  (utilizzato per MiniLM-L6-v2 nei retrieval)

---

## ğŸ¤– LLM APIs (Gemini / OpenAI / HF)
Integrazione con i principali modelli LLM utilizzati nel progetto per predizione e generazione degli artefatti di deception.

- `openai`
- `google-genai`
- `transformers`
- `tokenizers`
- `safetensors`

---

## ğŸ§ª Fine-Tuning (CodeLlama / LoRA / PEFT)
Dipendenze necessarie per addestramento leggero (LoRA) su dataset Cowrie + sequenze attaccante.

- `torch`
- `accelerate`
- `datasets`
- `peft`
- `bitsandbytes`  
  (quantizzazione 4/8-bit per GPU poco potenti)

---

## ğŸ“Š Machine Learning Utilities
Strumenti usati per normalizzazione, feature engineering, clustering comportamentale.

- `scikit-learn`
- `numpy`

---

## ğŸ” Nota
Tutte le librerie sono compatibili con Python **3.10+** e con ambienti virtuali standard (`venv`/`conda`).  
Per lâ€™ecosistema LLM Ã¨ consigliata una GPU NVIDIA con supporto CUDA, ma il sistema funziona anche in CPU per test, predizione e RAG.

## ğŸ“ Struttura del repository

```bash
Predictive_deception/
â”‚
â”œâ”€â”€ chroma_storage/                     # Database vettoriale ChromaDB
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ DB_checkpoint.txt
â”‚
â”œâ”€â”€ deception/                          # Motore di deception + defender runtime
â”‚   â”œâ”€â”€ scenarios/
â”‚   â”œâ”€â”€ brain.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ defender.py
â”‚   â”œâ”€â”€ host.key
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ session_handler.py
â”‚   â””â”€â”€ ssh_server.py
â”‚
â”œâ”€â”€ Honeypot/                           # Ambiente honeypot (Vagrant + Ansible)
â”‚   â”œâ”€â”€ Vagrantfile
â”‚   â”œâ”€â”€ playbook.yml
â”‚   â”œâ”€â”€ readme.txt
â”‚   â””â”€â”€ roles/
â”‚       â”œâ”€â”€ db_vettoriale/
â”‚       â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ defender/
â”‚       â”‚   â”œâ”€â”€ files/
â”‚       â”‚   â”‚   â””â”€â”€ defender.py
â”‚       â”‚   â”œâ”€â”€ tasks/
â”‚       â”‚   â””â”€â”€ vars/
â”‚       â”œâ”€â”€ env_python/
â”‚       â”‚   â”œâ”€â”€ tasks/
â”‚       â”‚   â””â”€â”€ vars/
â”‚       â””â”€â”€ fakeshell/
â”‚           â”œâ”€â”€ files/
â”‚           â”‚   â”œâ”€â”€ fakeshell.py
â”‚           â”‚   â””â”€â”€ fakeshell_easy.py
â”‚           â”œâ”€â”€ handlers/
â”‚           â””â”€â”€ tasks/
â”‚
â”œâ”€â”€ inspectDataset/                     # Analisi e pulizia dataset Cowrie
â”‚   â”œâ”€â”€ analyze_and_clean.py
â”‚   â”œâ”€â”€ download_zenodo.py
â”‚   â””â”€â”€ merge_cowrie_datasets.py
â”‚
â”œâ”€â”€ prompting/                          # Motore predittivo LLM
â”‚   â”œâ”€â”€ core_rag.py
â”‚   â”œâ”€â”€ core_topk.py
â”‚   â”œâ”€â”€ evaluate_gemini_rag.py
â”‚   â”œâ”€â”€ evaluate_gemini_topk.py
â”‚   â”œâ”€â”€ evaluate_ollama_rag.py
â”‚   â”œâ”€â”€ evaluate_ollama_topk.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

â¸»
## ğŸ§­ Workflow del progetto (script principali)

| Step | Script / File                                                | Descrizione |
|------|--------------------------------------------------------------|-------------|
| 1ï¸âƒ£  | `inspectDataset/download_zenodo.py`                          | Scarica automaticamente i dataset Cowrie da Zenodo e li salva nella cartella `data/` per lâ€™analisi successiva. |
| 2ï¸âƒ£  | `inspectDataset/analyze_and_clean.py`                        | Analizza i log Cowrie, normalizza i comandi, rimuove rumore/duplicati e genera versioni RAW/CLEAN in formato JSONL con statistiche. |
| 3ï¸âƒ£  | `inspectDataset/merge_cowrie_datasets.py`                    | Unisce piÃ¹ file puliti in un unico dataset e produce lo split train/test (es. `cowrie_TRAIN.jsonl`, `cowrie_TEST.jsonl`) per gli esperimenti. |
| 4ï¸âƒ£  | `prompting/core_rag.py`                                      | Implementa il motore RAG: crea/usa il database vettoriale in `chroma_storage/` e fornisce funzioni di retrieval contestuale per le predizioni. |
| 5ï¸âƒ£  | `prompting/core_topk.py`                                     | Fornisce la logica generica di predizione Top-k (senza RAG), riutilizzabile da Gemini e modelli locali. |
| 6ï¸âƒ£  | `prompting/evaluate_gemini_topk.py`                          | Valuta il modello Gemini in modalitÃ  Top-k pura, calcolando accuratezza Top-1/Top-5 sulle sessioni di test. |
| 7ï¸âƒ£  | `prompting/evaluate_gemini_rag.py`                           | Valuta Gemini integrato con RAG (ChromaDB), usando contesto + retrieval per migliorare la predizione del prossimo comando. |
| 8ï¸âƒ£  | `prompting/evaluate_ollama_topk.py`                          | Esegue test su modelli locali (es. CodeLlama via Ollama) in modalitÃ  Top-k senza RAG, per confrontarli con Gemini. |
| 9ï¸âƒ£  | `prompting/evaluate_ollama_rag.py`                           | Valuta modelli locali integrati con RAG, combinando vector search + LLM per la next-command prediction. |
| ğŸ”Ÿ  | `Honeypot/Vagrantfile` + `Honeypot/playbook.yml`              | Definisce e configura lâ€™ambiente honeypot tramite Vagrant + Ansible (VM, utenti, Python, log, ruoli Ansible, ecc.). |
| 1ï¸âƒ£1ï¸âƒ£ | `Honeypot/roles/fakeshell/files/fakeshell.py`             | Implementa una fake shell avanzata nella VM: prompt realistico, esecuzione comandi e logging di ogni comando in `/var/log/fakeshell.json`. |
| 1ï¸âƒ£2ï¸âƒ£ | `Honeypot/roles/defender/files/defender.py`                 | Versione deployabile del Defender: segue il log della fake shell, usa RAG+Gemini per predire i prossimi comandi e crea artefatti di deception nel filesystem della VM. |
| 1ï¸âƒ£3ï¸âƒ£ | `deception/main.py` + `deception/ssh_server.py` + `deception/session_handler.py` | Avvia il server SSH honeypot, utile se si vuole testare l'ambiente in locale senza VM. |
| 1ï¸âƒ£4ï¸âƒ£ | `deception/defender.py`                                      | Defender runtime principale: legge i comandi in tempo reale, interroga RAG+LLM e genera file/configurazioni esca in base alle predizioni. |
| 1ï¸âƒ£5ï¸âƒ£ | `deception/brain.py`                                         | Coordina lâ€™intelligenza di alto livello della deception (strategie, scenari, logica su quando/come creare artefatti). |
| 1ï¸âƒ£6ï¸âƒ£ | `deception/config.py`                                        | Centralizza configurazioni condivise: path del log, posizione del DB vettoriale, porte, chiavi API e selezione dello scenario di deception. |


## ğŸ§  Note metodologiche

- I modelli lavorano meglio con **prompt compatti** e **in inglese**, come quelli costruiti in  
  `prompting/core_topk.py` e `prompting/core_rag.py`.

- Le predizioni in alcuni casi vanno  **pulite e normalizzate**:  
  usa le funzioni di parsing e confronto in `prompting/utils.py`  
  (es. normalizzazione comandi, split per riga, gestione spazi).

- Ãˆ utile testare diversi valori di **context length** (`CONTEXT_LEN`), in particolare con:
  - `prompting/evaluate_gemini_topk.py`
  - `prompting/evaluate_gemini_rag.py`
  - `prompting/evaluate_ollama_topk.py`
  - `prompting/evaluate_ollama_rag.py`
  - e nel runtime del defender (`deception/defender.py`), dove `CONTEXT_LEN` controlla quanto â€œpassatoâ€ vede il modello.

- Per valutare correttamente i modelli conviene combinare:
  - **Exact Match** (giÃ  calcolato negli script di valutazione)
  - **Confronto normalizzato**, usando le utility di `prompting/utils.py`
    per ridurre lâ€™effetto di differenze minori (spazi, quote, ecc.).

- Quando usi API esterne come **Gemini** (`evaluate_gemini_*.py`, `deception/defender.py`):
  - tieni conto di **rate limit** e possibili errori temporanei;
  - mantieni una logica di retry/sleep leggera, cosÃ¬ da non bloccare gli esperimenti o il defender.

- Per esperimenti su larga scala Ã¨ preferibile usare modelli locali via **Ollama**:
  - `prompting/evaluate_ollama_topk.py`
  - `prompting/evaluate_ollama_rag.py`  
  sono pensati per girare a lungo, con loop su centinaia/migliaia di sessioni.

- Usa sempre dataset **puliti e coerenti**, generati dalla pipeline:
  - `inspectDataset/download_zenodo.py` â†’ download dei log Cowrie
  - `inspectDataset/analyze_and_clean.py` â†’ pulizia, normalizzazione e statistiche
  - `inspectDataset/merge_cowrie_datasets.py` â†’ merge e split train/test  
  in modo da ridurre rumore, comandi rari inutili e formati incoerenti.

- Per il **RAG**:
  - indicizza una sola volta in `chroma_storage/` usando la logica di `prompting/core_rag.py`;
  - riutilizza lo stesso DB vettoriale sia negli script di valutazione (`evaluate_*_rag.py`)  
    sia nel defender (`deception/defender.py`) tramite `VectorContextRetriever`;
  - evita di ricreare la collection a ogni esecuzione: il retriever Ã¨ giÃ  pensato per lavorare su un DB esistente.
---

## ğŸ”® Lavori futuri

### Fine-tuning specializzato dei modelli LLM
- Passare dallâ€™uso zero-/few-shot a un **fine-tuning supervisionato** di un modello locale (es. CodeLlama via Ollama).
- Usare come dati:
  - sequenze di comandi dai log Cowrie (`TRAIN/TEST`);
  - log Vagrant (`fakeshell.json`);
  - sessioni da honeypot reali in produzione.
- Obiettivo: adattare il modello alla distribuzione reale dei comandi SSH, ridurre hallucination e migliorare la coerenza delle sequenze multi-step.  
  Gemini rimane il riferimento â€œcloudâ€, il CodeLlama fine-tunato il motore locale per la predizione *next-command*.

### Predizione multi-step e pianificazione della deception
- Estendere la predizione dal singolo comando Top-k a **brevi traiettorie di comandi** (2â€“5 step).
- Questo permette di:
  - pre-caricare catene di artefatti lungo possibili percorsi dellâ€™attaccante (ricognizione â†’ config â†’ esfiltrazione);
  - stimare lâ€™intenzione probabile (es. credential harvesting vs. lateral movement);
  - orchestrare strategie di deception a livello di **sessione**, non solo di singolo comando.
- Particolarmente utile contro script automatizzati e tool di brute forcing con sequenze deterministiche.

### Deception dinamica guidata dal modello
- Evolvere dalla creazione di pochi file isolati a una **deception dinamica** in cui il modello:
  - suggerisce insiemi coerenti di directory, log, chiavi e configurazioni fittizie;
  - contribuisce a simulare interi scenari di sistema (es. server applicativo con database â€œfantasmaâ€);
  - adatta la profonditÃ  dellâ€™ingaggio in base al profilo dellâ€™attaccante osservato.
- In questa visione, `brain.py` diventa un **orchestratore di scenari**, che combina:
  - predizioni LLM,
  - knowledge storico dal RAG,
  - policy di deception definite dallâ€™analista.

### Apprendimento continuo dai log dellâ€™honeypot
- Passare da un ChromaDB statico a un **RAG aggiornato continuamente**, in cui:
  - le nuove sessioni loggate da `fakeshell.py` e dal server SSH vengono periodicamente normalizzate e indicizzate;
  - il knowledge base si arricchisce con attacchi recenti, seguendo lâ€™evoluzione delle tecniche offensive.
- Integrare una pipeline automatica per:
  - il retraining o fine-tuning incrementale del modello locale;
  - lâ€™aggiornamento del RAG con i nuovi log.
- Lâ€™honeypot diventa cosÃ¬ una sorgente continua di dati per migliorare il motore predittivo, non solo un consumatore di knowledge storico.

## ğŸ“š Riferimenti

- ğŸ **Cowrie Honeypot** â†’ https://github.com/cowrie/cowrie
- ğŸª¤ **Canarytokens** â†’ https://canarytokens.org / https://github.com/thinkst/canarytokens
- ğŸ’» **Ollama** â†’ https://ollama.com / https://github.com/ollama/ollama
- ğŸŒ **OpenRouter API** â†’ https://openrouter.ai
- ğŸ§ª **CyberLab Honeynet Dataset (Zenodo)** â†’ https://zenodo.org/records/3687527
- ğŸ¼ **PANDAcap SSH Dataset** â†’ https://zenodo.org/records/3759652
- ğŸ­ **SIHD â€“ Smart Industrial Honeypot Dataset (IEEE)** â†’ https://ieee-dataport.org/documents/sihd-smart-industrial-honeypot-dataset
- ğŸ•µï¸ **HoneySELK Cyber Attacks Dataset (IEEE)** â†’ https://ieee-dataport.org/open-access/dataset-cyber-attacks-honeyselk

### ğŸ“˜ Key Papers
- ğŸ“„ Nawrocki et al. (2016) â€” "A Survey on Honeypot Software and Data Analysis"  
- ğŸ¤– Deng et al. (2023) â€” "PentestGPT: Evaluating LLMs for Automated Penetration Testing"  
- ğŸ›¡ï¸ Alata et al. â€” "Lessons Learned from High-Interaction Honeypot Deployment"  
- ğŸ¦ Whitham â€” "Canary Tokens and Deception"  

---

## ğŸ‘¥ Autori

| | | |
|:--:|:--:|:--:|
| <a href="https://github.com/BlackRaffo70"><img src="https://github.com/BlackRaffo70.png" width="110" alt="avatar Raffaele Neri"></a> | <a href="https://github.com/melomatte"><img src="https://github.com/melomatte.png" width="110" alt="avatar Matteo Melotti"></a> | <a href="https://github.com/kikeeeee"><img src="https://github.com/kikeeeee.png" width="110" alt="avatar Enrico Borsetti"></a> |
| **Raffaele Neri**<br/>[@BlackRaffo70](https://github.com/BlackRaffo70) | **Matteo Melotti**<br/>[@melottimatteo](https://github.com/melomatte) | **Enrico Borsetti**<br/>[@enricoborsetti](https://github.com/kikeeeee) |

---

ğŸ“˜ *Progetto di ricerca:*  
**ğŸ¯ Predictive Deception â€“ LLM-based Command Anticipation in SSH Honeypots**  
UniversitÃ  di Bologna â€“ Corso di Laurea Magistrale in Ingegneria Informatica  

ğŸ‘¨â€ğŸ« *Docente referente:* **Prof. Michele Colajanni**
