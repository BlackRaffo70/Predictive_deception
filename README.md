<img width="1024" height="233" alt="image" src="https://github.com/user-attachments/assets/e210dcce-57f2-4470-a895-780896dbe45f" />


 ðŸ¯ Obiettivo del progetto

Tradizionalmente, gli honeypot reagiscono ai comandi malevoli dopo la loro esecuzione.
Questo progetto esplora un approccio innovativo: predictive deception, dove un LLM (Large Language Model) analizza in tempo reale la sequenza dei comandi inviati da un attaccante per predire il prossimo comando probabile.

Questo consente di:
	â€¢	Pre-posizionare file o artefatti falsi prima che lâ€™attaccante li richieda.
	â€¢	Attivare canary tokens o logging avanzato al momento dellâ€™accesso.
	â€¢	Aumentare lâ€™engagement dellâ€™attaccante e migliorare la qualitÃ  dellâ€™intelligence raccolta.

â¸»

ðŸ“¦ Contenuto tipico del progetto

**requirements.txt:**
```bash
requests
tqdm
difflib
argparse
```

â¸»

ðŸ“ Struttura del repository

Predictive_deception/
â”‚
â”œâ”€â”€ analyze_cowrie_dataset.py         â†’ Analizza dataset Cowrie e crea sessioni
â”œâ”€â”€ build_predictive_pairs.py         â†’ Crea coppie (context â†’ next)
â”œâ”€â”€ evaluate_ollama.py                â†’ Valutazione modelli locali via Ollama
â”œâ”€â”€ evaluate_LLM_OpenRouter.py        â†’ Valutazione modelli via API OpenRouter
â”œâ”€â”€ inspect_cowrie_json.py            â†’ Ispeziona dataset grezzo
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cowrie_2020-02-29.json        â†’ Dataset originale Cowrie
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ cowrie_sessions.jsonl         â†’ Sessioni SSH estratte
â”‚   â”œâ”€â”€ predictive_pairs.jsonl        â†’ Coppie (context â†’ next)
â”‚   â”œâ”€â”€ ollama_results.jsonl          â†’ Risultati modelli locali
â”‚   â”œâ”€â”€ results.jsonl                 â†’ Risultati modelli API
â”‚   â””â”€â”€ summary.json                  â†’ Metriche riassuntive
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


â¸»

ðŸ§­ **Workflow del progetto**
```bash
Step	Script	Input	Output	Descrizione
1ï¸âƒ£	inspect_cowrie_json.py	data/cowrie_2020-02-29.json	â€”	Ispeziona il file raw per verificare la struttura
2ï¸âƒ£	analyze_cowrie_dataset.py	Cowrie JSON	output/cowrie_sessions.jsonl	Estrae eventi e comandi per sessione
3ï¸âƒ£	build_predictive_pairs.py	output/cowrie_sessions.jsonl	output/predictive_pairs.jsonl	Genera coppie sliding-window (context â†’ next)
4ï¸âƒ£	evaluate_ollama.py	output/predictive_pairs.jsonl	output/ollama_results.jsonl	Valuta modelli locali via Ollama
5ï¸âƒ£	evaluate_LLM_OpenRouter.py	output/predictive_pairs.jsonl	output/results.jsonl, output/summary.json	Valuta modelli cloud via OpenRouter API
```

â¸»

ðŸš€ **Esempi di utilizzo rapido**

1ï¸âƒ£ Analisi dataset Cowrie:
```bash
python analyze_cowrie_dataset.py --input data/cowrie_2020-02-29.json --output output/cowrie
```
2ï¸âƒ£ Generare coppie di predizione (sliding window):
```bash
python build_predictive_pairs.py --input output/cowrie_sessions.jsonl --output output/predictive_pairs.jsonl --context-len 1
```
3ï¸âƒ£ Valutare modello locale con Ollama:

```bash
ollama pull mistral:7b-instruct-q4_0
ollama serve &
python evaluate_ollama.py --data output/predictive_pairs.jsonl --model mistral:7b-instruct-q4_0 --n 200 --temp 0.1
```
4ï¸âƒ£ Valutare modello via OpenRouter (API):

```bash
export OPENROUTER_API_KEY="sk-or-xxxxxxxx"
python evaluate_LLM_OpenRouter.py --input output/predictive_pairs.jsonl --model deepseek/deepseek-r1:free --n 200
```

â¸»

ðŸ“Š Output di esempio

Esempio di riga in ollama_results.jsonl:
```bash
{"context": ["whoami", "uname -a"], "expected": "cat /etc/passwd", "predicted": "cat /etc/shadow", "similarity": 0.85, "match": 0, "raw_response": "cat /etc/shadow"}
```
Esempio di file summary.json:
```bash
{
  "total_new": 200,
  "exact_acc": 0.12,
  "near_matches_jaccard>=0.80": 0.35,
  "error_rate": 0.05,
  "model": "mistral:7b-instruct-q4_0",
  "generated_at": "2025-11-04T10:00:00Z"
}
```

â¸»

ðŸ§  Note metodologiche
	â€¢	Prompt brevi e in inglese migliorano la precisione.
	â€¢	Estrarre sempre la prima riga valida del comando previsto.
	â€¢	Testare vari context-len (1â€“5 comandi precedenti).
	â€¢	Misurare sia exact match che similaritÃ  testuale (Jaccard / SequenceMatcher).
	â€¢	Usare rate-limit e backoff per le API gratuite.
	â€¢	Preferire Ollama locale o GPU universitaria per batch lunghi.

â¸»

ðŸ”§ Possibili estensioni future
	â€¢	Fine-tuning su dataset SSH per predizioni piÃ¹ accurate.
	â€¢	Introduzione di top-k accuracy (predizione di piÃ¹ candidati).
	â€¢	Integrazione diretta con sistemi honeypot (Cowrie / CanaryTokens).
	â€¢	Analisi semantica dei pattern di attacco (ricognizione, persistence, ecc.).

â¸»

ðŸ“š Riferimenti
	â€¢	Cowrie Honeypot: https://github.com/cowrie/cowrie
	â€¢	Canarytokens: https://canarytokens.org / https://github.com/thinkst/canarytokens
	â€¢	Ollama: https://ollama.com / https://github.com/ollama/ollama
	â€¢	OpenRouter: https://openrouter.ai
â¸»
UniversitÃ  di Bologna â€“ Corso di Laurea Magistrale in Ingegneria Informatica
Progetto di ricerca a cura di:

Docente referente: Prof. Michele Colajanni

â¸»

